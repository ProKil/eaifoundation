{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from termios import TIOCM_DSR\n",
    "import warnings\n",
    "import random\n",
    "import json\n",
    "import sys\n",
    "import cv2\n",
    "import tqdm\n",
    "import os\n",
    "import copy\n",
    "\n",
    "from ai2thor.controller import Controller\n",
    "import ai2thor\n",
    "from allenact_plugins.ithor_plugin.ithor_util import (\n",
    "    horizontal_to_vertical_fov,\n",
    ")\n",
    "from boolset.tasks_and_samplers import (\n",
    "    AgentPose,\n",
    "    HouseAugmenter,\n",
    "    ProcTHORDataset,\n",
    "    Vector3,\n",
    ")\n",
    "\n",
    "import prior\n",
    "from allenact.embodiedai.sensors.vision_sensors import DepthSensor\n",
    "from PIL import Image\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "# configurations\n",
    "THOR_COMMIT_ID = \"345a5fc046f25305c66367a484c9ae297107c877\"\n",
    "CAMERA_WIDTH = 224\n",
    "CAMERA_HEIGHT = 224\n",
    "HORIZONTAL_FIELD_OF_VIEW = 100\n",
    "STEP_SIZE = 0.2\n",
    "ROTATION_DEGREES = 45.0\n",
    "VISIBILITY_DISTANCE = 1.5\n",
    "\n",
    "# dataset = prior.load_dataset(\"procthor-10k\")\n",
    "# train_scenes = dataset[\"train\"]\n",
    "# val_scenes = dataset[\"val\"]\n",
    "# SCENES = ProcTHORDataset(\n",
    "#     [i for i in train_scenes] + [i for i in val_scenes]\n",
    "# )\n",
    "\n",
    "# define dataset collection parameters\n",
    "TRAIN = False if sys.argv[1] == \"test\" else True\n",
    "NUM_ANCHORS = 1000 if TRAIN else 100\n",
    "NUM_STEPS = 4\n",
    "ROT_ANGLE = 30\n",
    "ACTIONS = [\"MoveAhead\", \"MoveBack\", \"RotateLeft\", \"RotateRight\"]\n",
    "IMG_ROOT = '../data/interactron/train' if TRAIN else '../data/interactron/test'\n",
    "ANN_PATH = '../data/interactron/annotations/interactron_v1_train.json' if TRAIN \\\n",
    "    else '../data/interactron/annotations/interactron_v1_test.json'\n",
    "CTRL = Controller(\n",
    "    commit_id=THOR_COMMIT_ID,\n",
    "    server_class=ai2thor.fifo_server.FifoServer,\n",
    "    include_private_scenes=False,\n",
    "    fastActionEmit=True,\n",
    "    snapToGrid=False,\n",
    "    autoSimulation=False,\n",
    "    autoSyncTransforms=True,\n",
    "    width=CAMERA_WIDTH,\n",
    "    height=CAMERA_HEIGHT,\n",
    "    fieldOfView=horizontal_to_vertical_fov(\n",
    "        horizontal_fov_in_degrees=HORIZONTAL_FIELD_OF_VIEW,\n",
    "        width=CAMERA_WIDTH,\n",
    "        height=CAMERA_HEIGHT,\n",
    "    ),\n",
    "    makeAgentsVisible=True,\n",
    "    visibilityScheme=\"Distance\",\n",
    "    agentMode=\"arm\",\n",
    "    rotateStepDegrees=ROTATION_DEGREES,\n",
    "    visibilityDistance=VISIBILITY_DISTANCE,\n",
    "    gridSize=STEP_SIZE,\n",
    "    useMassThreshold=True,\n",
    "    massThreshold=10,\n",
    "    platform=\"CloudRendering\",\n",
    "    branch=\"nanna-grasp-force\",\n",
    "    scene=\"ArchitecTHOR-Val-01\",\n",
    "    renderSemanticSegmentation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_down_frame(\n",
    "    controller: Controller, resolution: Optional[Tuple[int, int]] = None\n",
    "):\n",
    "    if controller.last_event.frame is None:\n",
    "        controller.step(\"Pass\")\n",
    "\n",
    "    start_res = controller.last_event.frame.shape[:2]\n",
    "\n",
    "    if resolution != start_res:\n",
    "        controller.step(\"ChangeResolution\", x=resolution[1], y=resolution[0])\n",
    "\n",
    "    # Setup the top-down camera\n",
    "    event = controller.step(action=\"GetMapViewCameraProperties\", raise_for_failure=True)\n",
    "    pose = copy.deepcopy(event.metadata[\"actionReturn\"])\n",
    "\n",
    "    bounds = event.metadata[\"sceneBounds\"][\"size\"]\n",
    "    max_bound = max(bounds[\"x\"], bounds[\"z\"])\n",
    "\n",
    "    pose[\"fieldOfView\"] = 50\n",
    "    pose[\"position\"][\"y\"] += 1.1 * max_bound\n",
    "    pose[\"orthographic\"] = False\n",
    "    pose[\"farClippingPlane\"] = 50\n",
    "    pose[\"nearClippingPlane\"] = 18.5\n",
    "    del pose[\"orthographicSize\"]\n",
    "\n",
    "    # add the camera to the scene\n",
    "    event = controller.step(\n",
    "        action=\"AddThirdPartyCamera\",\n",
    "        **pose,\n",
    "        skyboxColor=\"white\",\n",
    "        raise_for_failure=True,\n",
    "    )\n",
    "    out = event.third_party_camera_frames[-1]\n",
    "\n",
    "    if resolution != start_res:\n",
    "        controller.step(\"ChangeResolution\", x=start_res[1], y=start_res[0])\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = get_top_down_frame(CTRL, resolution=(1080, 1920))\n",
    "im = Image.fromarray(A)\n",
    "im.save(\"frame.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('allenact-foundation')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "274807b8c2819fefd2fafb9f21b207a947784604b1c1aa41996dd2931a3f5b8e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
